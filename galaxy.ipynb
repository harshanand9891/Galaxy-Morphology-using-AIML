{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN33LGPS78Ksew1ZmxW2QeZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshanand9891/Galaxy-Morphology-using-AIML/blob/main/galaxy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uCJEBIeUCFMy"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import utils, layers, models\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import itertools"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install astroNN"
      ],
      "metadata": {
        "id": "mXEK0psyCzBp",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**#LOAD DATA**"
      ],
      "metadata": {
        "id": "cs6kAbscDRuz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from astroNN.datasets import load_galaxy10\n",
        "images, labels = load_galaxy10()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_lssf66DYW0",
        "outputId": "d411c3b6-b66f-4294-ab69-d2fd25b3cd61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root/.astroNN/datasets/Galaxy10_DECals.h5 was found!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ensure data is of the correct type\n"
      ],
      "metadata": {
        "id": "2UpbjkYHDcoy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels = labels.astype(np.float32)\n",
        "images = images.astype(np.float32)"
      ],
      "metadata": {
        "id": "TjIoxKuWDj74"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split data into training and test sets"
      ],
      "metadata": {
        "id": "4idmuCzxEIK6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_x, test_x = train_test_split(np.arange(labels.shape[0]), test_size=0.1)\n",
        "train_images, train_labels = images[train_x], labels[train_x]\n",
        "test_images, test_labels = images[test_x], labels[test_x]\n"
      ],
      "metadata": {
        "id": "al87Q52XEL-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define image labels"
      ],
      "metadata": {
        "id": "l7wA7v7lN_ZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "imageLabel = [\n",
        "    \"Disturbed\", \"Merging\", \"Round Smooth\", \"In-between Round Smooth\",\n",
        "    \"Cigar Shaped Smooth\", \"Barred Spiral\", \"Unbarred Tight Spiral\",\n",
        "    \"Unbarred Loose Spiral\", \"Edge-on Galaxies without Bulge\",\n",
        "    \"Edge-on Galaxies with Bulge\"\n",
        "]"
      ],
      "metadata": {
        "id": "ZrDXRl40OBF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot sample images"
      ],
      "metadata": {
        "id": "ZQk0jNciOD0X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(ncols=10, nrows=10, figsize=(20, 20))\n",
        "index = 0\n",
        "for i in range(10):\n",
        "    for j in range(10):\n",
        "        axes[i, j].set_title(imageLabel[int(labels[index])])\n",
        "        axes[i, j].imshow(images[index].astype(np.uint8))\n",
        "        axes[i, j].get_xaxis().set_visible(False)\n",
        "        axes[i, j].get_yaxis().set_visible(False)\n",
        "        index += 1\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "bWm7a8_aOGqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vision Transformer parameters"
      ],
      "metadata": {
        "id": "MlwJfDE8OMoq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.001\n",
        "weight_decay = 0.0001\n",
        "batch_size = 256\n",
        "num_epochs = 70\n",
        "image_size = 72\n",
        "patch_size = 6\n",
        "num_patches = (image_size // patch_size) ** 2\n",
        "projection_dim = 64\n",
        "num_heads = 4\n",
        "transformer_units = [projection_dim * 2, projection_dim]\n",
        "transformer_layers = 8\n",
        "mlp_head_units = [2048, 1024]"
      ],
      "metadata": {
        "id": "cKOPNDDQON-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data augmentation"
      ],
      "metadata": {
        "id": "ATic0uy_OQSF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_augmentation = models.Sequential(\n",
        "    [\n",
        "        layers.Normalization(),\n",
        "        layers.Resizing(image_size, image_size),\n",
        "        layers.RandomFlip(\"horizontal\"),\n",
        "        layers.RandomRotation(factor=0.02),\n",
        "        layers.RandomZoom(height_factor=0.2, width_factor=0.2),\n",
        "    ],\n",
        "    name=\"data_augmentation\",\n",
        ")"
      ],
      "metadata": {
        "id": "1aB-583VOSbB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adapt normalization layer to the training data"
      ],
      "metadata": {
        "id": "_QxSqVMUOVZV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_augmentation.layers[0].adapt(train_images)\n"
      ],
      "metadata": {
        "id": "Jida-eQaOXgi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data generator for augmentation"
      ],
      "metadata": {
        "id": "WGur3sDhOZln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=30, zoom_range=0.2, width_shift_range=0.1, height_shift_range=0.1,\n",
        "    horizontal_flip=True, vertical_flip=False\n",
        ")\n",
        "datagen.fit(train_images)\n"
      ],
      "metadata": {
        "id": "bbsnbXzNOb-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MLP function"
      ],
      "metadata": {
        "id": "N49YA5-sOfdL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mlp(x, hidden_units, dropout_rate):\n",
        "    for units in hidden_units:\n",
        "        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n",
        "        x = layers.Dropout(dropout_rate)(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "isPeGjsUOiGb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Patch and PatchEncoder classes"
      ],
      "metadata": {
        "id": "E9PqaucLOkV3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Patches(layers.Layer):\n",
        "    def __init__(self, patch_size):\n",
        "        super(Patches, self).__init__()\n",
        "        self.patch_size = patch_size\n",
        "\n",
        "    def call(self, images):\n",
        "        batch_size = tf.shape(images)[0]\n",
        "        patches = tf.image.extract_patches(\n",
        "            images=images,\n",
        "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
        "            strides=[1, self.patch_size, self.patch_size, 1],\n",
        "            rates=[1, 1, 1, 1],\n",
        "            padding=\"VALID\",\n",
        "        )\n",
        "        patch_dims = patches.shape[-1]\n",
        "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
        "        return patches\n",
        "\n",
        "class PatchEncoder(layers.Layer):\n",
        "    def __init__(self, num_patches, projection_dim):\n",
        "        super(PatchEncoder, self).__init__()\n",
        "        self.num_patches = num_patches\n",
        "        self.projection = layers.Dense(units=projection_dim)\n",
        "        self.position_embedding = layers.Embedding(input_dim=num_patches, output_dim=projection_dim)\n",
        "\n",
        "    def call(self, patch):\n",
        "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
        "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
        "        return encoded"
      ],
      "metadata": {
        "id": "5hzU7jj_Om5y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create Vision Transformer classifier"
      ],
      "metadata": {
        "id": "WXrgy5F7Oy4Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_vit_classifier(input_shape, num_classes):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    augmented = data_augmentation(inputs)\n",
        "    patches = Patches(patch_size)(augmented)\n",
        "    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
        "\n",
        "    for _ in range(transformer_layers):\n",
        "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
        "        attention_output = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
        "        )(x1, x1)\n",
        "        x2 = layers.Add()([attention_output, encoded_patches])\n",
        "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
        "        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n",
        "        encoded_patches = layers.Add()([x3, x2])\n",
        "\n",
        "    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
        "    representation = layers.Flatten()(representation)\n",
        "    representation = layers.Dropout(0.5)(representation)\n",
        "    features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.5)\n",
        "    logits = layers.Dense(num_classes)(features)\n",
        "\n",
        "    model = models.Model(inputs=inputs, outputs=logits)\n",
        "    return model"
      ],
      "metadata": {
        "id": "xrwA2zgfO1PI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot confusion matrix"
      ],
      "metadata": {
        "id": "52qsKFyPO51g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(cm, class_names):\n",
        "    figure = plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(class_names))\n",
        "    plt.xticks(tick_marks, class_names, rotation=45)\n",
        "    plt.yticks(tick_marks, class_names)\n",
        "\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j], horizontalalignment=\"center\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')"
      ],
      "metadata": {
        "id": "m3ueyAn0O8Rw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run experiment"
      ],
      "metadata": {
        "id": "gkRLM3d2PDEG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_experiment(model, X_train, y_train, X_test, y_test):\n",
        "    optimizer = tfa.optimizers.AdamW(learning_rate=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "        metrics=[keras.metrics.CategoricalAccuracy(name=\"accuracy\")],\n",
        "    )\n",
        "\n",
        "    history = model.fit(\n",
        "        x=X_train, y=y_train, batch_size=batch_size, epochs=num_epochs, validation_split=0.1,\n",
        "    )\n",
        "\n",
        "    y_test_arg = np.argmax(y_test, axis=1)\n",
        "    Y_pred = np.argmax(model.predict(X_test), axis=1)\n",
        "\n",
        "    print('Confusion Matrix')\n",
        "    cm = confusion_matrix(y_test_arg, Y_pred)\n",
        "    print(cm)\n",
        "\n",
        "    target_names = imageLabel\n",
        "    print(classification_report(y_test_arg, Y_pred, target_names=target_names))\n",
        "\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title('Model Accuracy')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "    plt.show()\n",
        "\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('Model Loss')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "    plt.show()\n",
        "\n",
        "    pred = model.predict(X_test)\n",
        "    pred_label = np.argmax(pred, axis=1)\n",
        "    actual_label = np.argmax(y_test, axis=1)\n",
        "\n",
        "    cm = confusion_matrix(pred_label, actual_label)\n",
        "    plot_confusion_matrix(cm, imageLabel)\n",
        "\n",
        "    fig, axes = plt.subplots(ncols=7, nrows=3, sharex=False, sharey=True, figsize=(17, 8))\n",
        "    index = 0\n",
        "    for i in range(3):\n",
        "        for j in range(7):\n",
        "            axes[i, j].set_title(f'Actual: {imageLabel[actual_label[index]]}\\nPredicted: {imageLabel[pred_label[index]]}')\n",
        "            axes[i, j].imshow(test_images[index].astype(np.uint8), cmap='gray')\n",
        "            axes[i, j].get_xaxis().set_visible(False)\n",
        "            axes[i, j].get_yaxis().set_visible(False)\n",
        "            index += 1\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "BG4S-LpiPIUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define input shape and number of classes"
      ],
      "metadata": {
        "id": "deXVZenzPRE9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (72, 72, 3)  # Example shape, adjust based on your data\n",
        "num_classes = len(imageLabel)"
      ],
      "metadata": {
        "id": "hb6OdBcvPTuk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create and run the Vision Transformer classifier"
      ],
      "metadata": {
        "id": "BKAeG_t6PXjU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vit_classifier = create_vit_classifier(input_shape, num_classes)\n",
        "history = run_experiment(vit_classifier, train_images, train_labels, test_images, test_labels)\n"
      ],
      "metadata": {
        "id": "SOAywmXjPYVr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}